server.name=serving-app-service
server.port=8183

spring.servlet.multipart.max-file-size=10000MB
spring.servlet.multipart.max-request-size=10000MB
#===========mysql=================
#数据源配置
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.druid.initial-size=1
spring.datasource.druid.min-idle=3
spring.datasource.druid.max-active=10
#配置监控页面访问登录名称
spring.datasource.druid.stat-view-servlet.login-username=admin
#配置监控页面访问密码
spring.datasource.druid.stat-view-servlet.login-password=admin
#是否开启慢sql查询监控
spring.datasource.druid.filter.stat.log-slow-sql=true
spring.datasource.druid.filters=stat,wall,log4j

#慢SQL执行时间
spring.datasource.druid.filter.stat.slow-sql-millis=1000

spring.datasource.url=jdbc:mysql://${mysql.address}:3307
#spring.datasource.url=jdbc:mysql://localhost:3307
spring.datasource.username=root
spring.datasource.password=234520
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
spring.datasource.initialization-mode=always
spring.datasource.schema=classpath:/schema.sql

#============== kafka ===================
# 指定kafka 代理地址，可以多个
spring.kafka.bootstrap-servers=${kafka.address}:9092
spring.kafka.receiver-topics=hdfsmanager-send-servingapp
spring.kafka.send-topics=send-hdfsmanager

#=============== provider  =======================

spring.kafka.producer.retries=0
# 每次批量发送消息的数量
spring.kafka.producer.batch-size=16384
spring.kafka.producer.buffer-memory=33554432

# 指定消息key和消息体的编解码方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

#=============== consumer  =======================
# 指定默认消费者group id
spring.kafka.consumer.group-id=serving-app

spring.kafka.consumer.auto-offset-reset=latest
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.auto-commit-interval=100

# 指定消息key和消息体的编解码方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

pagehelper.helper-dialect=mysql
pagehelper.reasonable=true
pagehelper.support-methods-arguments=true
pagehelper.params=count=countSql


servingapp.path=/Users/xujun/data/audio-deep-flow/nfs/servingapp
servingapp.hdfsUrl=hdfs://172.27.133.18:8020/user/xj/audio_4
audio-deep-flow.k8s.namespace=audio-deep-flow
audio-deep-flow.servingapp.job.image=tensorflow/serving:latest
#audio-deep-flow.buildmodel.job.image=build_model_launcher:1.0