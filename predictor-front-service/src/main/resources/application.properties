server.name=predictor-front-service
server.port=8280

spring.servlet.multipart.max-file-size=10000MB
spring.servlet.multipart.max-request-size=10000MB
#===========mysql=================
#数据源配置
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.druid.initial-size=1
spring.datasource.druid.min-idle=3
spring.datasource.druid.max-active=10
#配置监控页面访问登录名称
spring.datasource.druid.stat-view-servlet.login-username=admin
#配置监控页面访问密码
spring.datasource.druid.stat-view-servlet.login-password=admin
#是否开启慢sql查询监控
spring.datasource.druid.filter.stat.log-slow-sql=true
spring.datasource.druid.filters=stat,wall,log4j

#慢SQL执行时间
spring.datasource.druid.filter.stat.slow-sql-millis=1000

spring.datasource.url=jdbc:mysql://${mysql.address}:3307
#spring.datasource.url=jdbc:mysql://localhost:3307
spring.datasource.username=root
spring.datasource.password=234520
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
spring.datasource.initialization-mode=always
spring.datasource.schema=classpath:/schema.sql

#============== kafka ===================
# 指定kafka 代理地址，可以多个
spring.kafka.bootstrap-servers=${kafka.address}
spring.kafka.receiver-topics=${kafka.receiverTopics}
spring.kafka.send-topics=${kafka.sendTopics}

#=============== provider  =======================

spring.kafka.producer.retries=0
# 每次批量发送消息的数量
spring.kafka.producer.batch-size=16384
spring.kafka.producer.buffer-memory=33554432

# 指定消息key和消息体的编解码方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

#=============== consumer  =======================
# 指定默认消费者group id
spring.kafka.consumer.group-id=predictor-front-service

spring.kafka.consumer.auto-offset-reset=latest
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.auto-commit-interval=100

# 指定消息key和消息体的编解码方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

pagehelper.helper-dialect=mysql
pagehelper.reasonable=true
pagehelper.support-methods-arguments=true
pagehelper.params=count=countSql

predictor.url=${predictor.url}

